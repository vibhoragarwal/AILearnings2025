services:
  nim-llm:
    container_name: nim-llm-ms
    image: nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:1.13.1
    shm_size: 16GB
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    user: "${USERID}"
    ports:
    - "8999:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      # Automatic profile detection
      NIM_MODEL_PROFILE: ${NIM_MODEL_PROFILE-""}
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${LLM_MS_GPU_ID:-1}']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/v1/health/ready')"]
      interval: 10s
      timeout: 20s
      retries: 100
    profiles: ["", "rag"]

  nemoretriever-embedding-ms:
    container_name: nemoretriever-embedding-ms
    image: nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.10.0
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    ports:
    - "9080:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      NIM_TRT_ENGINE_HOST_CODE_ALLOWED: 1
    user: "${USERID}"
    shm_size: 16GB
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${EMBEDDING_MS_GPU_ID:-0}']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10m
    profiles: ["", "rag", "ingest", "text-embed", "vlm-final-answer"]

  nemoretriever-vlm-embedding-ms:
    container_name: nemoretriever-vlm-embedding-ms
    image: nvcr.io/nvidia/nemo-microservices/llama-3.2-nemoretriever-1b-vlm-embed-v1:1.7.0
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    ports:
    - "9081:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      NIM_TRT_ENGINE_HOST_CODE_ALLOWED: 1
    user: "${USERID}"
    shm_size: 16GB
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${VLM_EMBEDDING_MS_GPU_ID:-0}']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10m
    profiles: ["vlm-embed"]

  nemoretriever-ranking-ms:
    container_name: nemoretriever-ranking-ms
    image: nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.8.0
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    ports:
    - "1976:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    user: "${USERID}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 10s
      timeout: 20s
      retries: 100
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${RANKING_MS_GPU_ID:-0}']
              capabilities: [gpu]
    profiles: ["", "rag", "vlm-final-answer"]

  page-elements:
    image: ${YOLOX_IMAGE:-nvcr.io/nim/nvidia/nemoretriever-page-elements-v2}:${YOLOX_TAG:-1.5.0}
    shm_size: 16gb
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    user: root
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NIM_TRITON_RATE_LIMIT=3
      - NGC_API_KEY=${NIM_NGC_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - CUDA_VISIBLE_DEVICES=0
      - NIM_TRITON_MAX_BATCH_SIZE=${PAGE_ELEMENTS_BATCH_SIZE:-32}
      - NIM_TRITON_CUDA_MEMORY_POOL_MB=${PAGE_ELEMENTS_CUDA_MEMORY_POOL_MB:-2048}
      - NIM_TRITON_CPU_THREADS_PRE_PROCESSOR=${PAGE_ELEMENTS_CPU_THREADS_PRE_PROCESSOR:-2}
      - NIM_TRITON_CPU_THREADS_POST_PROCESSOR=${PAGE_ELEMENTS_CPU_THREADS_POST_PROCESSOR:-1}
      - OMP_NUM_THREADS=2
      # NIM OpenTelemetry Settings
      - NIM_ENABLE_OTEL=0
      - NIM_OTEL_SERVICE_NAME=page-elements
      - NIM_OTEL_TRACES_EXPORTER=otlp
      - NIM_OTEL_METRICS_EXPORTER=console
      - NIM_OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
      - NIM_ENABLE_OTEL=true
      # Triton OpenTelemetry Settings
      - TRITON_OTEL_URL=http://otel-collector:4318/v1/traces
      - TRITON_OTEL_RATE=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${YOLOX_MS_GPU_ID:-0}']
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["", "ingest"]

  graphic-elements:
    image: ${YOLOX_GRAPHIC_ELEMENTS_IMAGE:-nvcr.io/nim/nvidia/nemoretriever-graphic-elements-v1}:${YOLOX_GRAPHIC_ELEMENTS_TAG:-1.5.0}
    shm_size: 16gb
    ports:
      - "8003:8000"
      - "8004:8001"
      - "8005:8002"
    user: root
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NIM_TRITON_RATE_LIMIT=3
      - NGC_API_KEY=${NIM_NGC_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - CUDA_VISIBLE_DEVICES=0
      - NIM_TRITON_MAX_BATCH_SIZE=${GRAPHIC_ELEMENTS_BATCH_SIZE:-32}
      - NIM_TRITON_CUDA_MEMORY_POOL_MB=${GRAPHIC_ELEMENTS_CUDA_MEMORY_POOL_MB:-2048}
      - OMP_NUM_THREADS=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${YOLOX_GRAPHICS_MS_GPU_ID:-0}']
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["", "ingest"]

  table-structure:
    image: ${YOLOX_TABLE_STRUCTURE_IMAGE:-nvcr.io/nim/nvidia/nemoretriever-table-structure-v1}:${YOLOX_TABLE_STRUCTURE_TAG:-1.5.0}
    shm_size: 16gb
    ports:
      - "8006:8000"
      - "8007:8001"
      - "8008:8002"
    user: root
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NIM_TRITON_RATE_LIMIT=3
      - NGC_API_KEY=${NIM_NGC_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - CUDA_VISIBLE_DEVICES=0
      - NIM_TRITON_MAX_BATCH_SIZE=${TABLE_STRUCTURE_BATCH_SIZE:-32}
      - NIM_TRITON_CUDA_MEMORY_POOL_MB=${TABLE_STRUCTURE_CUDA_MEMORY_POOL_MB:-2048}
      - OMP_NUM_THREADS=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids:  ['${YOLOX_TABLE_MS_GPU_ID:-0}']
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["", "ingest"]

  paddle:
    image: ${PADDLE_IMAGE:-nvcr.io/nim/baidu/paddleocr}:${PADDLE_TAG:-1.5.0}
    shm_size: 16gb
    ports:
      - "8009:8000"
      - "8010:8001"
      - "8011:8002"
    user: root
    environment:
      - OMP_NUM_THREADS=${OCR_OMP_NUM_THREADS:-8}
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=${NIM_NGC_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - CUDA_VISIBLE_DEVICES=0
      - NIM_TRITON_RATE_LIMIT=3
      - NIM_TRITON_CUDA_MEMORY_POOL_MB=${OCR_CUDA_MEMORY_POOL_MB:-3072}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids:  ['${OCR_MS_GPU_ID:-${PADDLE_MS_GPU_ID:-0}}']
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["", "ingest"]

  nemoretriever-ocr:
    image: ${NEMORETRIEVER_OCR_IMAGE:-nvcr.io/nvidia/nemo-microservices/nemoretriever-ocr-v1}:${NEMORETRIEVER_OCR_TAG:-1.1.0}
    shm_size: 2gb
    ports:
      - "8012:8000"
      - "8013:8001"
      - "8014:8002"
    user: root
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NIM_TRITON_RATE_LIMIT=1
      - NVIDIA_API_KEY=${NGC_API_KEY:-nvidiaapikey}
      - NGC_API_KEY=${NGC_API_KEY:-nvidiaapikey}
      - CUDA_VISIBLE_DEVICES=0
      - NIM_TRITON_MAX_BATCH_SIZE=${NEMORETRIEVER_OCR_BATCH_SIZE:-32}
      - NIM_TRITON_CUDA_MEMORY_POOL_MB=${NEMORETRIEVER_OCR_CUDA_MEMORY_POOL_MB:-2048}
      - NIM_TRITON_CPU_THREADS_PRE_PROCESSOR=${NEMORETRIEVER_OCR_CPU_THREADS_PRE_PROCESSOR:-2}
      - NIM_TRITON_CPU_THREADS_POST_PROCESSOR=${NEMORETRIEVER_OCR_CPU_THREADS_POST_PROCESSOR:-1}
      - OMP_NUM_THREADS=${NEMORETRIEVER_OCR_OMP_NUM_THREADS:-1}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${OCR_MS_GPU_ID:-${PADDLE_MS_GPU_ID:-0}}"]
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["nemoretriever-ocr"]

  # Optional NIM microservices
  nemoretriever-parse:
    image: ${NEMORETRIEVER_PARSE_IMAGE:-nvcr.io/nim/nvidia/nemoretriever-parse}:${NEMORETRIEVER_PARSE_TAG:-1.2}
    ports:
      - "8015:8000"
      - "8016:8001"
      - "8017:8002"
    user: root
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NVIDIA_API_KEY=${NGC_API_KEY:-nvidiaapikey}
      - NGC_API_KEY=${NGC_API_KEY:-nvidiaapikey}
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${NEMORETRIEVER_PARSE_MS_GPU_ID:-1}']
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["nemoretriever-parse"]

  audio:
    image: ${AUDIO_IMAGE:-nvcr.io/nim/nvidia/riva-asr}:${AUDIO_TAG:-1.3.0}
    shm_size: 2gb
    ports:
      - "8021:50051"  # grpc
      - "8022:9000"  # http
    user: root
    environment:
      - NIM_TAGS_SELECTOR=name=parakeet-1-1b-ctc-riva-en-us,mode=ofl
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=${NIM_NGC_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${AUDIO_MS_GPU_ID:-0}"]
              capabilities: [gpu]
    runtime: nvidia
    profiles: ["audio"]

  vlm-ms:
    container_name: nemo-vlm-microservice
    image: nvcr.io/nim/nvidia/llama-3.1-nemotron-nano-vl-8b-v1:1.3.1
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    ports:
    - "1977:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    user: "${USERID}"
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/v1/health/ready')"]
      interval: 10s
      timeout: 20s
      retries: 100
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${VLM_MS_GPU_ID:-5}']
              capabilities: [gpu]
    profiles: ["vlm", "vlm-final-answer"]

networks:
  default:
    name: nvidia-rag
