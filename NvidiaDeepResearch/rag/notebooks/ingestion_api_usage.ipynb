{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650fa9f0",
   "metadata": {},
   "source": [
    "# Ingestion API Usage\n",
    "\n",
    "This notebook demonstrates how to interact with the ingestion APIs to upload and index documents for retrieval-augmented generation (RAG) applications. It showcases the different APIs needed to create a collection, upload documents to the created collection using Milvus Vector DB. It also showcases different APIs to manage uploaded documents and existing collections effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5726313-f5ab-48fb-b747-c790ebaafe48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Ensure the ingestor-server container is running before executing the notebook by following the steps in [Get Started](../docs/deploy-docker-self-hosted.md).\n",
    "- Replace `BASE_URL` with the actual server URL if the API is hosted on another system.\n",
    "- You can customize the directory path (`../data/multimodal`) with the correct location of your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58505d5-5436-449a-b316-b943a1a57797",
   "metadata": {},
   "source": [
    "#### 1. Install Dependencies and import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78246c4e-040d-4e06-8ed3-edb88ca0c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiohttp\n",
    "import json\n",
    "import os\n",
    "\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a494be7-ffee-4dfb-968f-c5300f6ba0a2",
   "metadata": {},
   "source": [
    "#### 2. Setup Base Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807ea21-f9b8-408b-b2ee-318bef308d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPADDRESS = (\n",
    "    \"ingestor-server\"\n",
    "    if os.environ.get(\"AI_WORKBENCH\", \"false\") == \"true\"\n",
    "    else \"localhost\"\n",
    ")  # Replace this with the correct IP address\n",
    "INGESTOR_SERVER_PORT = \"8082\"\n",
    "BASE_URL = f\"http://{IPADDRESS}:{INGESTOR_SERVER_PORT}\"  # Replace with your server URL\n",
    "\n",
    "\n",
    "async def print_response(response):\n",
    "    \"\"\"Helper to print API response.\"\"\"\n",
    "    try:\n",
    "        response_json = await response.json()\n",
    "        print(json.dumps(response_json, indent=2))\n",
    "    except aiohttp.ClientResponseError:\n",
    "        print(await response.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f85b3-767b-4e8f-82da-9d5c7069d609",
   "metadata": {},
   "source": [
    "#### 3. Health Check Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint performs a health check on the server. It returns a 200 status code if the server is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e53c4-909b-4b04-975f-c598f33bd797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async def fetch_health_status():\n",
    "    \"\"\"Fetch health status asynchronously.\"\"\"\n",
    "    url = f\"{BASE_URL}/v1/health\"\n",
    "    params = {\"check_dependencies\": \"True\"}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url, params=params) as response:\n",
    "            await print_response(response)\n",
    "\n",
    "\n",
    "# Run the async function\n",
    "await fetch_health_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850cbb2",
   "metadata": {},
   "source": [
    "#### 4. Create collection Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint is used to create a collection in the vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e658845",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_collection(\n",
    "    collection_name: list = None,\n",
    "    embedding_dimension: int = 2048,\n",
    "    metadata_schema: list = [],\n",
    "):\n",
    "    data = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"embedding_dimension\": embedding_dimension,\n",
    "        \"metadata_schema\": metadata_schema,\n",
    "    }\n",
    "\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                f\"{BASE_URL}/v1/collection\", json=data, headers=HEADERS\n",
    "            ) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            return 500, {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# [Optional]: Define schema for metadata fields\n",
    "metadata_schema = [\n",
    "    {\n",
    "        \"name\": \"timestamp\",\n",
    "        \"type\": \"datetime\",  # Field of time datetime (i.e string in ISO 8601 format)\n",
    "        \"description\": \"Following field would store the timestamp of when the document was created\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"meta_field_1\",\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Following field would contain the description for the document\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Call create collection method\n",
    "await create_collection(\n",
    "    collection_name=\"multimodal_data\",\n",
    "    metadata_schema=metadata_schema,  # Optional argument, can be commented if metadata is not to be inserted\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334abfc-5832-4e39-8793-818b5265aa1d",
   "metadata": {},
   "source": [
    "#### 4. Upload Document Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint uploads new documents to the vector store. \n",
    "1. You can specify the collection name where the documents should be stored. \n",
    "2. The collection to which the documents are being uploaded must exist in the vector database.\n",
    "3. The documents which are uploaded must not exist in the collection. If the documents already exists, to reingest existing files in the provided collection, replace `session.post(...)` with `session.patch(...)`\n",
    "4. To speed up the ingestion process, the multiple files can be passed in a single request as showcased below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709ab2e-c1de-42d4-96b2-eb104f8bd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "FILEPATHS = [\n",
    "    \"../data/multimodal/embedded_table.pdf\",\n",
    "    \"../data/multimodal/functional_validation.pdf\",\n",
    "    \"../data/multimodal/woods_frost.pdf\",\n",
    "    \"../data/multimodal/multimodal_test.pdf\",\n",
    "    \"../data/multimodal/table_test.pdf\",\n",
    "    \"../data/multimodal/woods_frost.docx\",\n",
    "]\n",
    "\n",
    "# [Optional]: Add filename specific custom metadata\n",
    "# Note: timestamp metadata field must be in ISO 8601 format so following operands are supported: \"==\", \"<=\",\n",
    "CUSTOM_METADATA = [\n",
    "    {\n",
    "        \"filename\": \"multimodal_test.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2000-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"multimodal document\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"functional_validation.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2001-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"functional validation document\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"woods_frost.pdf\",\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": \"2002-05-15T10:23:00\",\n",
    "            \"meta_field_1\": \"multimodal document\",\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d611db2-c663-4014-bd6e-fb0a279a04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upload_documents(collection_name: str = \"\"):\n",
    "    data = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"blocking\": False,  # If True, upload is blocking; else async. Status API not needed when blocking\n",
    "        \"split_options\": {\"chunk_size\": 512, \"chunk_overlap\": 150},\n",
    "        \"custom_metadata\": CUSTOM_METADATA,\n",
    "        \"generate_summary\": False,  # Set to True to optionally generate summaries for all documents after ingestion\n",
    "    }\n",
    "\n",
    "    form_data = aiohttp.FormData()\n",
    "    for file_path in FILEPATHS:\n",
    "        form_data.add_field(\n",
    "            \"documents\",\n",
    "            open(file_path, \"rb\"),\n",
    "            filename=os.path.basename(file_path),\n",
    "            content_type=\"application/pdf\",\n",
    "        )\n",
    "\n",
    "    form_data.add_field(\"data\", json.dumps(data), content_type=\"application/json\")\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                f\"{BASE_URL}/v1/documents\", data=form_data\n",
    "            ) as response:  # Replace with session.patch for reingesting\n",
    "                await print_response(response)\n",
    "                # Return the response JSON for task_id extraction\n",
    "                response_json = await response.json()\n",
    "                return response_json\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Store the response and extract task_id\n",
    "upload_response = await upload_documents(collection_name=\"multimodal_data\")\n",
    "task_id = upload_response.get(\"task_id\") if upload_response else None\n",
    "print(f\"Extracted task_id: {task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554475c3-b8dc-41d9-94b9-fb833a46e2fc",
   "metadata": {},
   "source": [
    "#### 5. Get Task Status Endpoint:\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint is used to get task status of upload documents task. When task is `\"FINISHED\"`, this endpoint can be used to get status report of the upload task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668bb85-3b77-4c43-9274-61e5037e3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_task_status(task_id: str):\n",
    "    params = {\n",
    "        \"task_id\": task_id,\n",
    "    }\n",
    "\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(\n",
    "                f\"{BASE_URL}/v1/status\", params=params, headers=HEADERS\n",
    "            ) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            return 500, {\"error\": str(e)}\n",
    "\n",
    "# Use the extracted task_id from the upload_documents response\n",
    "if task_id:\n",
    "    await get_task_status(task_id=task_id)\n",
    "else:\n",
    "    print(\"No task_id available. Please run the upload_documents cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191cd7f-02d1-45c6-90a7-f3ca86c4046a",
   "metadata": {},
   "source": [
    "#### 6. Get Documents Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint retrieves a list of documents ingested into the vector store for a specified collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250bcc6-2137-40d2-95ff-6202faff4fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async def fetch_documents(collection_name: str = \"\"):\n",
    "    url = f\"{BASE_URL}/v1/documents\"\n",
    "    params = {\"collection_name\": collection_name}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "await fetch_documents(collection_name=\"multimodal_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9e3c-2092-4d6b-9ff7-64d33730337b",
   "metadata": {},
   "source": [
    "#### 7. Delete Documents Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint deletes specified documents from the vector store. The documents are identified by its filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5ebcd-f741-491c-a797-ee4fd15c9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "async def delete_documents(collection_name: str = \"\", file_names: list[str] = []):\n",
    "    url = f\"{BASE_URL}/v1/documents\"\n",
    "    params = {\"collection_name\": collection_name}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.delete(url, params=params, json=file_names) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "await delete_documents(\n",
    "    collection_name=\"multimodal_data\",\n",
    "    file_names=[\"embedded_table.pdf\", \"table_test.pdf\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9bfd5-b943-4eed-874b-9067fdfe06ca",
   "metadata": {},
   "source": [
    "#### 8. Get Collections Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint retrieves a list of all collection names available on the server. Collections are used to organize documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114bb1-f0f0-4444-859f-d4dc66fa9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_collections():\n",
    "    url = f\"{BASE_URL}/v1/collections\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "await fetch_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97e846",
   "metadata": {},
   "source": [
    "#### 9. Delete Collections Endpoint\n",
    "\n",
    "**Purpose:**\n",
    "This endpoint deletes list of provided collection names available on the specified vector database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def delete_collections(collection_names: list[str] = \"\"):\n",
    "    url = f\"{BASE_URL}/v1/collections\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.delete(url, json=collection_names) as response:\n",
    "                await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "await delete_collections(collection_names=[\"multimodal_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c212878-6925-4497-a6a5-89ecd5911cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
